{"steps":[{"type":"step","value":[{"type":"h2","value":[{"type":"text","value":"1. Introduction"}]},{"type":"p","value":[{"type":"text","value":"Imagine you’re a cattologist, trying to identify <b>different groups</b> of species of cats (rocks / minerals). You go out into the field to collect measurements of <i>chonkiness</i> and <i>fur color</i>—key features which you believe are important in their differentiation."}]}]},{"type":"step","value":[{"type":"p","value":[{"type":"text","value":"So you have at hand measurements of 100 cats you’ve encountered."}]}]},{"type":"step","value":[{"type":"p","value":[{"type":"text","value":"Visualizing them as a scatter plot, it turns out that you can conveniently identify <b>distinct clusters</b>—cats with similar measurements must be from the same species."}]}]},{"type":"step","value":[{"type":"p","value":[{"type":"text","value":"However, this is admittedly a contrived example—real-life datasets don’t necessarily look as elegant, and we are typically interested in more than two features. This makes it non-trivial to visualize, and picking out clusters through visual observation alone is near futile."}]}]},{"type":"step","value":[{"type":"p","value":[{"type":"text","value":"Hence, given a dataset of observations with features we care about, is there a way to <i>automatically</i> demarcate clusters from them? In machine learning, we call such methods <b>clustering algorithms</b>, and they are <b>unsupervised</b>—we don’t have any information about the ground-truth clusters, and are tasked to infer structure just from the features we have at hand."}]}]},{"type":"step","value":[{"type":"h2","value":[{"type":"text","value":"2. K-Means"}]},{"type":"p","value":[{"type":"text","value":"How can we determine if any two observations belong to the same cluster? Intuitively, we want to assign observations that are similar to the same cluster, and at the same time placing dissimilar observations in different clusters."}]}]},{"type":"step","value":[{"type":"p","value":[{"type":"text","value":"We’ll first need to define a <b>notion of similarity</b> between two observations. While there are many ways to do so, a natural choice would the straight line distance—or better known as the Euclidean distance—between them."}]}]},{"type":"step","value":[{"type":"p","value":[{"type":"text","value":"The k-means algorithm requires that the users specify how many clusters they expect beforehand. Then, instead of explicitly learning the cluster assignments for each data point, it does so implicitly by learning what the exemplary, or <b>prototypical</b> example from each cluster looks like."}]}]},{"type":"step","value":[{"type":"p","value":[{"type":"text","value":"To determine which cluster a data point belongs to, we just have to check which prototype it is the closest to."}]}]},{"type":"step","value":[{"type":"p","value":[{"type":"text","value":"Sample paragraph 1"}]},{"type":"p","value":[{"type":"text","value":"Sample paragraph 2"},{"type":"b","value":"Bolded word"}]}]}]}